@article{RAISSI2019686,
title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
journal = {Journal of Computational Physics},
volume = {378},
pages = {686-707},
year = {2019},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2018.10.045},
url = {https://www.sciencedirect.com/science/article/pii/S0021999118307125},
author = {M. Raissi and P. Perdikaris and G.E. Karniadakis},
keywords = {Data-driven scientific computing, Machine learning, Predictive modeling, Runge–Kutta methods, Nonlinear dynamics},
}

@misc{kharazmi2019variational,
      title={Variational Physics-Informed Neural Networks For Solving Partial Differential Equations}, 
      author={E. Kharazmi and Z. Zhang and G. E. Karniadakis},
      year={2019},
      eprint={1912.00873},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@misc{adamoptimizer,
  doi = {10.48550/ARXIV.1412.6980},
  url = {https://arxiv.org/abs/1412.6980},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Adam: A Method for Stochastic Optimization},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@InProceedings{xavierinitialization,
  title = 	 {Understanding the difficulty of training deep feedforward neural networks},
  author = 	 {Glorot, Xavier and Bengio, Yoshua},
  booktitle = 	 {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {249--256},
  year = 	 {2010},
  editor = 	 {Teh, Yee Whye and Titterington, Mike},
  volume = 	 {9},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Chia Laguna Resort, Sardinia, Italy},
  month = 	 {13--15 May},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf},
  url = 	 {https://proceedings.mlr.press/v9/glorot10a.html},

}

@misc{cyr2019,
  doi = {10.48550/ARXIV.1912.04862},
  url = {https://arxiv.org/abs/1912.04862},
  author = {Cyr, Eric C. and Gulian, Mamikon A. and Patel, Ravi G. and Perego, Mauro and Trask, Nathaniel A.},
  keywords = {Machine Learning (cs.LG), Numerical Analysis (math.NA), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  title = {Robust Training and Initialization of Deep Neural Networks: An Adaptive Basis Viewpoint},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{liu2021,
  doi = {10.48550/ARXIV.2107.08935},
  url = {https://arxiv.org/abs/2107.08935},
  author = {Liu, Min and Cai, Zhiqiang and Chen, Jingshuang},
  keywords = {Numerical Analysis (math.NA), FOS: Mathematics, FOS: Mathematics},
  title = {Adaptive Two-Layer ReLU Neural Network: I. Best Least-squares Approximation},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}

@article{moiola2014helmholtz,
  title={Is the Helmholtz equation really sign-indefinite?},
  author={Moiola, Andrea and Spence, Euan A},
  journal={Siam Review},
  volume={56},
  number={2},
  pages={274--312},
  year={2014},
  publisher={SIAM}
}

@article{henriquez2022,
  title={NEURAL NETWORK GALERKIN FEM FOR THE ONE-DIMENSIONAL
HELMHOLTZ IMPEDANCE PROBLEM IN HIGH FREQUENCY},
  author={Henríquez, Fernando and Houliston, S},
  journal={},
  volume={},
  number={},
  pages={},
  year={2022},
  publisher={}
}

@misc{liu2021init,
  doi = {10.48550/ARXIV.2107.10991},
  url = {https://arxiv.org/abs/2107.10991},
  author = {Liu, Xu and Zhang, Xiaoya and Peng, Wei and Zhou, Weien and Yao, Wen},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {A novel meta-learning initialization method for physics-informed neural networks},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{alkhalifah2021,
title = {Wavefield solutions from machine learned functions constrained by the Helmholtz equation},
journal = {Artificial Intelligence in Geosciences},
volume = {2},
pages = {11-19},
year = {2021},
issn = {2666-5441},
doi = {https://doi.org/10.1016/j.aiig.2021.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S2666544121000241},
author = {Tariq Alkhalifah and Chao Song and Umair bin Waheed and Qi Hao},
keywords = {Helmholtz equation, Wavefields, Modeling, Neural networks, Deep learning},
abstract = {Solving the wave equation is one of the most (if not the most) fundamental problems we face as we try to illuminate the Earth using recorded seismic data. The Helmholtz equation provides wavefield solutions that are dimensionally reduced, per frequency, compared to the time domain, which is useful for many applications, like full waveform inversion. However, our ability to attain such wavefield solutions depends often on the size of the model and the complexity of the wave equation. Thus, we use here a recently introduced framework based on neural networks to predict functional solutions through setting the underlying physical equation as a loss function to optimize the neural network (NN) parameters. For an input given by a location in the model space, the network learns to predict the wavefield value at that location, and its partial derivatives using a concept referred to as automatic differentiation, to fit, in our case, a form of the Helmholtz equation. We specifically seek the solution of the scattered wavefield considering a simple homogeneous background model that allows for analytical solutions of the background wavefield. Providing the NN with a reasonable number of random points from the model space will ultimately train a fully connected deep NN to predict the scattered wavefield function. The size of the network depends mainly on the complexity of the desired wavefield, with such complexity increasing with increasing frequency and increasing model complexity. However, smaller networks can provide smoother wavefields that might be useful for inversion applications. Preliminary tests on a two-box-shaped scatterer model with a source in the middle, as well as, the Marmousi model with a source at the surface demonstrate the potential of the NN for this application. Additional tests on a 3D model demonstrate the potential versatility of the approach.}
}

@article{sun2015,
	doi = {10.1098/rsos.140520},
	url = {https://doi.org/10.1098%2Frsos.140520},
	year = 2015,
	month = {jan},
	publisher = {The Royal Society},
	volume = {2},
	number = {1},
	pages = {140520},
	author = {Qiang Sun and Evert Klaseboer and Boo-Cheong Khoo and Derek Y. C. Chan},
	title = {Boundary regularized integral equation formulation of the Helmholtz equation in acoustics},
	journal = {Royal Society Open Science}
}

@book{graham2012,
  title={Numerical analysis of multiscale problems},
  author={Graham, Ivan G and Hou, Thomas Y and Lakkis, Omar and Scheichl, Robert},
  volume={83},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@misc{fan2018,
  doi = {10.48550/ARXIV.1811.09025},
  url = {https://arxiv.org/abs/1811.09025},
  author = {Fan, Shitao},
  keywords = {Optimization and Control (math.OC), FOS: Mathematics, FOS: Mathematics},
  title = {An Introduction to Krylov Subspace Methods},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{xu2016,
  doi = {10.48550/ARXIV.1611.01917},
  url = {https://arxiv.org/abs/1611.01917},
  author = {Xu, Jinchao and Zikatanov, Ludmil T},
  keywords = {Numerical Analysis (math.NA), FOS: Mathematics, FOS: Mathematics},
  title = {Algebraic Multigrid Methods},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
